{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8RfSObrC6D1v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import heapq\n",
        "\n",
        "class PriorityQueue:\n",
        "    def __init__(self):\n",
        "        self.elements = []\n",
        "\n",
        "    def empty(self):\n",
        "        return len(self.elements) == 0\n",
        "\n",
        "    def put(self, item, priority):\n",
        "        heapq.heappush(self.elements, (priority, item))\n",
        "\n",
        "    def get(self):\n",
        "        return heapq.heappop(self.elements)[1]\n",
        "\n",
        "\n",
        "# Node Class represents a state in the search tree.\n",
        "class Node:\n",
        "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
        "        self.state = state  # The current position of the agent in the grid.\n",
        "        self.parent = parent  # The node in the search tree that generated this node.\n",
        "        self.action = action  # The action taken to get to this state.\n",
        "        self.path_cost = path_cost  # Cost from the start node to this node.\n",
        "\n",
        "    # Comparison operator for priority queue.\n",
        "    def __lt__(self, other):\n",
        "        return self.path_cost < other.path_cost\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic(a, b):\n",
        "    \"\"\"\n",
        "    Calculate the Manhattan distance between two points a and b.\n",
        "\n",
        "    Parameters:\n",
        "    - a: Tuple representing the x and y coordinates of point a (e.g., (x1, y1))\n",
        "    - b: Tuple representing the x and y coordinates of point b (e.g., (x2, y2))\n",
        "\n",
        "    Returns:\n",
        "    - The Manhattan distance between points a and b.\n",
        "    \"\"\"\n",
        "    (x1, y1) = a\n",
        "    (x2, y2) = b\n",
        "    return abs(x1 - x2) + abs(y1 - y2)\n"
      ],
      "metadata": {
        "id": "4VXmZcsA6JF3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Environment***"
      ],
      "metadata": {
        "id": "48xh1uIX9nPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Class represents the grid and handles state transitions.\n",
        "class Environment:\n",
        "    def __init__(self, grid, start, goal):\n",
        "        self.grid = grid  # The grid layout where 1 represents an obstacle and 0 is free space.\n",
        "        self.initial = start  # Starting position of the agent.\n",
        "        self.goal = goal  # Goal position the agent aims to reach.\n",
        "        self.battery_level = 100  # Battery level starts at 100%\n",
        "        self.recharge_count = 0  # Initialize recharge count to 0.\n",
        "\n",
        "\n",
        "\n",
        "    # Returns the possible actions from a given state.\n",
        "    def actions(self, state):\n",
        "        possible_actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
        "        x, y = state\n",
        "\n",
        "        # Remove impossible actions based on grid boundaries and obstacles.\n",
        "        if x == 0 or self.grid[x - 1][y] == 1:\n",
        "            possible_actions.remove('UP')\n",
        "        if x == len(self.grid) - 1 or self.grid[x + 1][y] == 1:\n",
        "            possible_actions.remove('DOWN')\n",
        "        if y == 0 or self.grid[x][y - 1] == 1:\n",
        "            possible_actions.remove('LEFT')\n",
        "        if y == len(self.grid[0]) - 1 or self.grid[x][y + 1] == 1:\n",
        "            possible_actions.remove('RIGHT')\n",
        "\n",
        "        return possible_actions\n",
        "\n",
        "    # Returns the state resulting from taking a given action at a given state.\n",
        "    def result(self, state, action):\n",
        "        x, y = state\n",
        "\n",
        "        if self.battery_level >= 10:\n",
        "          if action == 'UP':\n",
        "              new_state = (x - 1, y)\n",
        "          elif action == 'DOWN':\n",
        "              new_state = (x + 1, y)\n",
        "          elif action == 'LEFT':\n",
        "              new_state = (x, y - 1)\n",
        "          elif action == 'RIGHT':\n",
        "              new_state = (x, y + 1)\n",
        "\n",
        "          # Update battery level\n",
        "          self.battery_level -= 10\n",
        "          if self.battery_level <= 0:\n",
        "              # Robot must recharge before continuing\n",
        "              self.recharge_battery()\n",
        "\n",
        "          return new_state\n",
        "\n",
        "        else:\n",
        "          return state\n",
        "\n",
        "\n",
        "    # Recharges the battery level to 100%.\n",
        "    def recharge_battery(self):\n",
        "        self.battery_level = 100\n",
        "        self.recharge_count += 1\n",
        "\n",
        "    # Checks if the goal has been reached.\n",
        "    def is_goal(self, state):\n",
        "        return state == self.goal\n",
        "\n",
        "    # Returns the current recharge count.\n",
        "    def get_recharge_count(self):\n",
        "        return self.recharge_count"
      ],
      "metadata": {
        "id": "_9IbE5AT6K4H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Agent***"
      ],
      "metadata": {
        "id": "NWzrxt8o9i6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    # Performs Uniform Cost Search to find the lowest cost path from the initial state to the goal.\n",
        "    def uniform_cost_search(self):\n",
        "        self.env.recharge_count = 0  # Reset recharge count\n",
        "        self.env.battery_level = 100  # Reset battery level\n",
        "        frontier = PriorityQueue()  # Priority queue for UCS.\n",
        "        frontier.put(Node(self.env.initial, path_cost=0), 0)\n",
        "        came_from = {self.env.initial: None}\n",
        "        cost_so_far = {self.env.initial: 0}\n",
        "\n",
        "        while not frontier.empty():\n",
        "            current_node = frontier.get()\n",
        "\n",
        "            if self.env.is_goal(current_node.state):\n",
        "                return self.reconstruct_path(came_from, current_node.state)\n",
        "\n",
        "            for action in self.env.actions(current_node.state):\n",
        "                new_state = self.env.result(current_node.state, action)\n",
        "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity; adjust if varying costs.\n",
        "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
        "                    cost_so_far[new_state] = new_cost\n",
        "                    priority = new_cost\n",
        "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
        "                    came_from[new_state] = current_node.state\n",
        "\n",
        "        return []\n",
        "\n",
        "\n",
        "    def a_star_search(self):\n",
        "        self.env.recharge_count = 0  # Reset recharge count\n",
        "        self.env.battery_level = 100  # Reset battery level\n",
        "        # The start node is created with a path cost of 0.\n",
        "        start_node = Node(self.env.initial, path_cost=0)\n",
        "        frontier = PriorityQueue()\n",
        "        frontier.put(start_node, 0)  # Priority is f-cost, initially the heuristic cost from start to goal\n",
        "        came_from = {self.env.initial: None}  # Tracks the best path to a node\n",
        "        cost_so_far = {self.env.initial: 0}  # Tracks the g-cost (cost so far to reach a node)\n",
        "\n",
        "        while not frontier.empty():\n",
        "            current_node = frontier.get()\n",
        "\n",
        "            if self.env.is_goal(current_node.state):\n",
        "                return self.reconstruct_path(came_from, current_node.state)\n",
        "\n",
        "            for action in self.env.actions(current_node.state):\n",
        "                new_state = self.env.result(current_node.state, action)\n",
        "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity\n",
        "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
        "                    cost_so_far[new_state] = new_cost\n",
        "                    priority = new_cost + heuristic(new_state, self.env.goal)  # f-cost = g-cost + h-cost\n",
        "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
        "                    came_from[new_state] = current_node.state\n",
        "\n",
        "        return []\n",
        "\n",
        "\n",
        "    def reconstruct_path(self, came_from, current):\n",
        "        path = []\n",
        "        while current in came_from:\n",
        "            path.append(current)\n",
        "            current = came_from[current]\n",
        "        path.append(self.env.initial)  # Start node is not in came_from\n",
        "        path.reverse()  # Reverse to get the path from start to goal\n",
        "        return path\n"
      ],
      "metadata": {
        "id": "2PIA6Te76MaK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the grid and the path explored\n",
        "def visualize_grid_and_path(grid, path):\n",
        "    grid_array = np.array(grid)  # Convert grid to numpy array for easy plotting.\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(grid_array, cmap='Greys', alpha=0.3)  # Grid background.\n",
        "\n",
        "    if path:  # Check if the path is not empty\n",
        "        start = path[0]\n",
        "        goal = path[-1]\n",
        "        ax.plot(start[1], start[0], 'bs', markersize=10)  # Start position in blue.\n",
        "        ax.plot(goal[1], goal[0], 'gs', markersize=10)  # Goal position in green.\n",
        "        xs, ys = zip(*path)  # Extract X and Y coordinates of the path.\n",
        "        ax.plot(ys, xs, 'r-', linewidth=2)  # Plot the path in red.\n",
        "\n",
        "    ax.set_xticks(np.arange(-.5, len(grid[0]), 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, len(grid), 1), minor=True)\n",
        "    ax.grid(which=\"minor\", color=\"b\", linestyle='-', linewidth=1)\n",
        "    ax.tick_params(which=\"minor\", size=0)\n",
        "    ax.tick_params(which=\"major\", bottom=False, left=False, labelbottom=False, labelleft=False)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "chJhFRWq6aAA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Random Grid Function\n",
        "def generate_random_grid(size, obstacle_probability):\n",
        "    return np.random.choice([0, 1], size=(size, size), p=[1-obstacle_probability, obstacle_probability])\n",
        "\n",
        "# Define the size of the grid and the probability of an obstacle in each cell\n",
        "grid_size = 10\n",
        "obstacle_probability = 0.2  # 20% chance of being an obstacle\n",
        "\n",
        "# Generate a random grid\n",
        "grid = generate_random_grid(grid_size, obstacle_probability)\n",
        "\n",
        "# Define start and goal positions\n",
        "start = (0, 0)\n",
        "goal = (grid_size - 1, grid_size - 1)\n",
        "\n",
        "# Ensure start and goal are not obstacles\n",
        "grid[start] = 0\n",
        "grid[goal] = 0\n",
        "\n",
        "\n",
        "# Create the environment and agent\n",
        "environment = Environment(grid, start, goal)\n",
        "agent_ucs = Agent(environment)\n",
        "agent_astar = Agent(environment)\n",
        "\n",
        "# Solve the problem with Uniform Cost Search\n",
        "solution_path_ucs = agent_ucs.uniform_cost_search()\n",
        "recharge_count_ucs = environment.get_recharge_count()\n",
        "print(\"UCS Solution Path:\", solution_path_ucs)\n",
        "print(\"UCS Recharge Count:\", recharge_count_ucs)\n",
        "\n",
        "# Solve the problem with the A* algorithm\n",
        "solution_path_astar = agent_astar.a_star_search()\n",
        "recharge_count_astar = environment.get_recharge_count()\n",
        "print(\"A* Solution Path:\", solution_path_astar)\n",
        "print(\"A* Recharge Count:\", recharge_count_astar)\n",
        "\n",
        "# Compare recharge counts and determine the best algorithm\n",
        "if recharge_count_ucs < recharge_count_astar:\n",
        "    print(\"Uniform Cost Search is more efficient in terms of energy management.\")\n",
        "elif recharge_count_astar < recharge_count_ucs:\n",
        "    print(\"A* Search is more efficient in terms of energy management.\")\n",
        "else:\n",
        "    print(\"Both algorithms have the same efficiency in terms of energy management.\")\n",
        "\n",
        "# Visualize the solution for Uniform Cost Search\n",
        "visualize_grid_and_path(grid, solution_path_ucs)\n",
        "\n",
        "# Visualize the solution for A* Search\n",
        "visualize_grid_and_path(grid, solution_path_astar)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "Y4WmFk4W6cB5",
        "outputId": "7bf0406d-592e-4342-a94e-724b34025b9d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UCS Solution Path: [(0, 0), (0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (4, 3), (5, 3), (6, 3), (7, 3), (7, 4), (7, 5), (8, 5), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9)]\n",
            "UCS Recharge Count: 20\n",
            "A* Solution Path: [(0, 0), (0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (4, 3), (5, 3), (6, 3), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9)]\n",
            "A* Recharge Count: 17\n",
            "A* Search is more efficient in terms of energy management.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARiklEQVR4nO3dsWtbiZ728SdzYxPua1tNMMtESmUwghSDs2+7ffqUrrPFXVhwP1V6w8I7jWv/D/kjFpspAkYwbDGyk0uYRop3CfFu9BaKf3PNbmzJOo7OZD8fuKi4JydPTnT1taJrn3uTyWQSAEjy3bIHANAeogBAEQUAiigAUEQBgCIKABRRAKDcn+WgT58+5c2bN1lfX8+9e/fuehMADZtMJnn//n2+//77fPfdl98PzBSFN2/epNfrNTYOgOUYDofpdrtf/O9nisL6+nqS5F/+ZZgffthoZtmCBoPkxYvk4CDZ3l72mimbZmPTbC43/eUvP6fb/fdlz0mSnJ7+n/z00w+tvE42Xe/nn8f553/u1ev5l8wUhct/Mvrhh438wz+0Iwpra9PHp0+TnZ3lbrlk02xsms3lpq2tZGvrv5Y75rMHD5Jko5XXyabZ3PQRgA+aASiiAEARBQCKKABQRAGAIgoAFFEAoIgCAGWmb16b16+/Jr/9Nv+ve/gwefy4+T0AzKbxKPz66/Tbuj98mP/XPngw/fZwYQBYjsb/+ei3324XhGT6627zDgOAZvhMAYAiCgAUUQCgiAIA5atG4V/z9xmmm3/N33/N3xaAGd3J9yl8yd/lr+nm7Gv+lgDMwT8fAVBEAYAiCgAUUQCgiAIARRQAKI1H4eHD6U87vY0HD6a/HoDlaPz7FB4/nv746//pp51uPkvyLtncTI5e/ff/3v0UAJbrTr557fHjL7y4r0wfVleSnZ27+J0BWITPFAAoogBAEQUAiigAUEQBgCIKABRRAKDM9X0Kg0Gytnb73+zJRbKa5ONF8vr49udJkpOTq49tYNNsbJrN5ZbhcIH/0TXscksbr5NN1xsMZjvu3mQymdx00Hg8TqfTSTJKsnHrUcN0081ZTvMovZze+jwAzGucpJPRaJSNjS+/js/1TuHgIHn69PaTbvoxF/M4OUl2d5PDw6TfX+xcTWnzpr294/R658uek2T61eb+/o7rdIM2XyebrtfG59MvvyQ//XTzcXNFYXt7wR9PcQc/5qLfb9+PzGjjpl7vPFtb42XPuMJ1mk0br5NNs2nT8+nDhz/NdJwPmgEoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAo9+c5eDBI1tZu/5s9uUhWk3y8SF4f3/48SXJycvWxDdq8aThc4C+uYZdbXKfrtfk62XS9Nj6fTk9nO+7eZDKZ3HTQeDxOp9NJMkqycetRw3TTzVlO8yi9zLgQgAaMk3QyGo2ysfHl1/G53ikcHCRPn95+0uazJO+Szc3k6NXtz5NMS7y7mxweJv3+YudqyuWmvb3j9Hrny56TZPqVyv7+Tiuvk03Xa/Mmz/HrtfE6/fJL8tNPNx83VxS2t5OdndtOSrIyfVhdWfA8f6Pfb+5cTen1zrO1NV72jCvaeJ1smk0bN3mOz6ZN1+nDhz/NdJwPmgEoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAo9+c5eDBI1tZu/5s9uUhWk3y8SF4f3/48SXJycvWxDS63DIcLXKSGXW5p43Wy6Xpt3uQ5fr02XqfT09mOuzeZTCY3HTQej9PpdJKMkmzcetQw3XRzltM8Si8zLgSgAeMknYxGo2xsfPl1fK53CgcHydOnt5+0+SzJu2RzMzl6dfvzJNMS7+4mh4dJv7/YuZpi02xsmk2bN+3tHafXO1/2nCTTr8b393daeZ3atOnoKHnx4ubj5orC9nays3PbSUlWpg+rKwue52/0+82dqyk2zcam2bRxU693nq2t8bJnXNHG69SmTeczNtwHzQAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFDmup9CY96+TbrdhU7x5CIZ5vONe1YW3LO+nrx8mTx/vuCJAP7Yvm4U1tenj58+JWdnC51qNUk3Sd4tOuqzH38UBeB/va8bhZcvpy++798vfKqPF8m7z7f2XF3kncLbt9NINbAJ4I/u60bh+fPGvhp/fTy9X/TRqwVvd9ftLvyuBeBb4YNmAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIAZa4fnT0YJGtrdzVlPicnVx9v68nF9IY9Hy+mP467DZuaZNNsbJrN5ZbhsCUvBPl9SxuvU5s2DQazHXdvMplMbjpoPB6n0+kkGSXZWGxZywzTTTdnOc2j9HK67DkAd2ScpJPRaJSNjS+/js/1TuHgYHpjmzY4OUl2d5PDw6Tfv/15Np8l+XwHt6NX7djUJJtmc7lpb+84vd75suckmX4FvL+/08rrZNP12vh8+uWX5Kefbj5urihsby94l7M70O8vuOnzrTxXV5r7sy286Q7YNJte7zxbW+Nlz7iijdfJptm06fn04cOfZjrOB80AFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQ5rqfwjft7duk213oFE8ukmE+37hnpZFVC2t00/p68vJl8vx5A8uANhKF9fXp46dPydnZQqdaTdJNkneLjmpO45t+/FEU4BsmCi9fTl/o3r9f+FQfL5J3n2/tudqSdwqNbXr7dhrOBq4T0F6i8Px5Y1/5vj6e3sP66FV7bgvY2KZud+F3UkD7+aAZgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAmetHZw8GydraXU2Zz8nJ1cc2+JY3PbmY3rDn48X0x3G3YVOTLrcMhy15guf3LW28TjZdr43Pp9PT2Y67N5lMJjcdNB6P0+l0koySbCy2jD+kYbrp5iyneZReZnx2AS0yTtLJaDTKxsaXX8fneqdwcDC9YUsbnJwku7vJ4WHS7y97zdS3vGnzWZLPd3A7etWOTU263LS3d5xe73zZc5JMv8rc399p5XVq4yZ/d9c7OkpevLj5uLmisL3dnjuKXer3bZrFwps+38pzdaW5P1sbr1Ovd56trfGyZ1zRxuvUxk3+7q53PmMvfdAMQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQLk/z8GDQbK2dldT5nNycvWxDb7lTU8uktUkHy+S18ft2NSkyy3DYUue4Pl9SxuvUxs3+bu73mAw23H3JpPJ5KaDxuNxOp1OklGSjcWW8Yc0TDfdnOU0j9LL6bLnAHMbJ+lkNBplY+PLr+NzvVM4OEiePl10WDNOTpLd3eTwMOn3l71m6lvetPksybtkczM5etXMpr294/R654udrCHD4Vr293dauamNzyfX6XptfC04OkpevLj5uLmisL2d7OzcdtLd6PdtmsXCm1amD6srzf3Zer3zbG2NmzlZQ9q4qY3PJ9dpNm3adD5jw33QDEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEC5P8/Bg0GytnZXU+ZzcnL1sQ2+5U1PLpLVJB8vktfHzWwaDlvyZMrvW9q4qY3PJ9fpem18LRgMZjvu3mQymdx00Hg8TqfTSTJKsrHYMv6Qhummm7Oc5lF6OV32HGBu4ySdjEajbGx8+XV8rncKBwfJ06eLDmvGyUmyu5scHib9/rLXTH3LmzafJXmXbG4mR6/asalJbd60t3ecXu982XOSTL8q39/faeV1sul6R0fJixc3HzdXFLa3k52d2066G/2+TbNYeNPK9GF1pbk/2zd5ne5Ar3eera3xsmdc0cbrZNP1zmf8usIHzQAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFDmup8C5O3bpNtd6BRPLpJhPt+4Z6WRVQtrdNP6evLyZfL8eQPL4OsSBWazvj59/PQpOTtb6FSrSbpJ8m7RUc1pfNOPP4oCf0iiwGxevpy+0L1/v/CpPl4k7z7f2nO1Je8UGtv09u00nA1cJ1gGUWA2z5839pXv6+Ppvb6PXrXnVoWNbep2F34nBcvkg2YAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBlrh+dPRgka2t3NWU+JydXH9vAptl8y5ueXExv2PPxYvrjuJvYNBy25H90+X3Lt/h316Q2bhoMZjvu3mQymdx00Hg8TqfTSTJKsrHYMviGDdNNN2c5zaP0crrsOfA3xkk6GY1G2dj48uv4XO8UDg6mNyJpg5OTZHc3OTxM+v1lr5myaTaXm/b2jtPrnS97TpLpV8D7+zsLX6fNZ0k+38Ht6NVim9p8ndq4qY3P8TZtOjpKXry4+bi5orC93Z47ZV3q922aRRs39Xrn2doaL3vGFQtfp8+38lxdae56t/E6tXFTG5/jbdp0PmPDfdAMQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQLk/z8GDQbK2dldT5nNycvWxDWyazeWW4bAlT6b8vmXR6/TkIllN8vEieX282LnafJ3auKmNz/E2bRoMZjvu3mQymdx00Hg8TqfTSTJKsrHYMviGDdNNN2c5zaP0crrsOfA3xkk6GY1G2dj48uv4XO8U/vKXn7O1teiwZgyHa9nf38nhYdLvL3vN1MlJsrub7O0dp9c7X/acJO2+Tt/ips1nSd4lm5vJ0at2bGqSTbNp46ajo+TFi5uPmysK3e6/Z2vrv2676U70+8nOzrJXXNXrnWdra7zsGVe08Tp9k5tWpg+rK8392b7J63QHbLre+Yxfp/qgGYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFDm+uY1AJr36+jX/PYfv8396x7++WEedx43ukUUAJbo19Gv2f5/2/nwnx/m/rUP7j/I4J8GjYbBPx8BLNFv//HbrYKQJB/+88Ot3mFcRxQAKKIAQBEFAIooAFD8v4/gLrx9m3S7C53iyUUyzOcb96w0smphNs1mnk1PPl1keMO9Dv66lvzff2xq3fVEAZq0vj59/PQpOTtb6FSrSbpJ8m7RUc2xaTbzbKpjW0IUoEkvXyY//pi8f7/wqT5eJO8+39pztSVfAds0m3k2ffx0kXfn19fjr2sNjruBKECTnj+f/qcBr4+Tp0+n93puyy0dbZrNPJtevz3O04OnX2fYDHzQDEARBQCKKABQRAGAIgoAS/Twzw/z4P6DW/3aB/cf5OGfHza6x//7CGCJHnceZ/BPA/dTAGDqcedx4y/ut+WfjwAoogBAEQUAiigAUEQBgCIKABRRAKDM9H0Kk8kkSfJv/5Ykf7rDObM7PU2ScY6OkvMb7lr0tQwG08dffkk+fHCdvuTyOtl0PZtmY9Nsfv55nOT31/MvuTe56Ygkp6en6fV6zSwDYGmGw2G619wqdqYofPr0KW/evMn6+nru3bvX6EAA7t5kMsn79+/z/fff57vvvvzJwUxRAOB/Bx80A1BEAYAiCgAUUQCgiAIARRQAKKIAQPn/1tS9cRXBtxgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARGUlEQVR4nO3dMW9bB3/24dt5LMF4KomLIbxISE8CBAEeAqldu3v3qNnv8BQooD2TdwEFmkWzvoM/RCEhgwGBQNAhlO0HRhbSamFYrdmB1j81WkuH4lF44l4XEHDIEXX7iOFPNCOde9PpdBoASPLNsgcA0B2iAEARBQCKKABQRAGAIgoAFFEAoNxvctDHjx/z+vXrrK+v5969e3e9CYCWTafTvHv3Lt9++22++ebLrwcaReH169cZDAatjQNgOUajUfr9/hf/faMorK+vJ0n+6Z9G+f77jXaWLWg4TJ49S46Oku3tZa+ZsakZm5q52vSXv/yUfv/flj0nSXJ+/jf58cfvO3mebLreTz9N8o//OKjn8y9pFIWrvzL6/vuN/P3fdyMKa2uz2729ZHd3uVuu2NSMTc1cbdraSra2/nO5Yz558CBJNjp5nmxq5qa3ALzRDEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiNfnhtXr/8kvz66/wf9/Bh8uhR+3sAaKb1KPzyy+zHut+/n/9jHzyY/Xi4MAAsR+t/ffTrr7cLQjL7uNu8wgCgHd5TAKCIAgBFFAAoogBA+V2j8C/524zSz7/kb3/PTwtAQ3fycwpf8v/y1/Tz6vf8lADMwV8fAVBEAYAiCgAUUQCgiAIARRQAKK1H4eHD2W87vY0HD2YfD8BytP5zCo8ezX799f/22043nyR5m2xuJicv/ue/dz0FgOW6kx9ee/ToC0/uK7Ob1ZVkd/cuPjMAi/CeAgBFFAAoogBAEQUAiigAUEQBgCIKAJS5fk5hOEzW1m7/yR5fJqtJPlwmL09vfz9Jcnb2+W0X2NSMTc1cbRmNFviPrmVXW7p4nmy63nDY7Lh70+l0etNBk8kkvV4vyTjJxq1HjdJPP69ynu8yyPmt7weAeU2S9DIej7Ox8eXn8bleKRwdJXt7t59006+5mMfZWbK/nxwfJzs7i91XW7q86eDgNIPBxbLnJJl9t3l4uOs83aDL58mm63Xx8fTzz8mPP9583FxR2N5e8NdT3MGvudjZ6d6vzOjipsHgIltbk2XP+Izz1EwXz5NNzXTp8fT+/Z8aHeeNZgCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQDK/XkOHg6TtbXbf7LHl8lqkg+XycvT299PkpydfX7bBV3eNBot8IVr2dUW5+l6XT5PNl2vi4+n8/Nmx92bTqfTmw6aTCbp9XpJxkk2bj1qlH76eZXzfJdBGi4EoAWTJL2Mx+NsbHz5eXyuVwpHR8ne3u0nbT5J8jbZ3ExOXtz+fpJZiff3k+PjZGdnsftqy9Wmg4PTDAYXy56TZPadyuHhbifPk03X6/Imj/HrdfE8/fxz8uOPNx83VxS2t5Pd3dtOSrIyu1ldWfB+/pudnfbuqy2DwUW2tibLnvGZLp4nm5rp4iaP8Wa6dJ7ev/9To+O80QxAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAuT/PwcNhsrZ2+0/2+DJZTfLhMnl5evv7SZKzs89vu+Bqy2i0wElq2dWWLp4nm67X5U0e49fr4nk6P2923L3pdDq96aDJZJJer5dknGTj1qNG6aefVznPdxmk4UIAWjBJ0st4PM7Gxpefx+d6pXB0lOzt3X7S5pMkb5PNzeTkxe3vJ5mVeH8/OT5OdnYWu6+22NSMTc10edPBwWkGg4tlz0ky+2788HC3k+epS5tOTpJnz24+bq4obG8nu7u3nZRkZXazurLg/fw3Ozvt3VdbbGrGpma6uGkwuMjW1mTZMz7TxfPUpU0XDRvujWYAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoc11PoTVv3iT9/kJ38fgyGeXThXtWFtyzvp48f548fbrgHQH8sf2+UVhfn91+/Ji8erXQXa0m6SfJ20VHffLDD6IA/J/3+0bh+fPZk++7dwvf1YfL5O2nS3uuLvJK4c2bWaRa2ATwR/f7RuHp09a+G395Orte9MmLBS931+8v/KoF4GvhjWYAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBlrl+dPRwma2t3NWU+Z2ef397W48vZBXs+XM5+HXcXNrXJpmZsauZqy2jUkSeC/Lali+epS5uGw2bH3ZtOp9ObDppMJun1eknGSTYWW9Yxo/TTz6uc57sMcr7sOQB3ZJKkl/F4nI2NLz+Pz/VK4ehodmGbLjg7S/b3k+PjZGfn9vez+STJpyu4nbzoxqY22dTM1aaDg9MMBhfLnpNk9h3w4eFuJ8+TTdfr4uPp55+TH3+8+bi5orC9veBVzu7Azs6Cmz5dynN1pb0/28Kb7oBNzQwGF9namix7xme6eJ5saqZLj6f37//U6DhvNANQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAECZ63oKX7U3b5J+f6G7eHyZjPLpwj0rraxaWKub1teT58+Tp09bWAZ0kSisr89uP35MXr1a6K5Wk/ST5O2io9rT+qYffhAF+IqJwvPnsye6d+8WvqsPl8nbT5f2XO3IK4XWNr15MwtnC+cJ6C5RePq0te98X57OrmF98qI7lwVsbVO/v/ArKaD7vNEMQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgzPWrs4fDZG3trqbM5+zs89su+Jo3Pb6cXbDnw+Xs13F3YVObrraMRh15gOe3LV08TzZdr4uPp/PzZsfdm06n05sOmkwm6fV6ScZJNhZbxh/SKP308yrn+S6DNHx0AR0ySdLLeDzOxsaXn8fneqVwdDS7YEsXnJ0l+/vJ8XGys7PsNTNf86bNJ0k+XcHt5EU3NrXpatPBwWkGg4tlz0ky+y7z8HC3k+epi5t87a53cpI8e3bzcXNFYXu7O1cUu7KzY1MTC2/6dCnP1ZX2/mxdPE+DwUW2tibLnvGZLp6nLm7ytbveRcNeeqMZgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgHJ/noOHw2Rt7a6mzOfs7PPbLviaNz2+TFaTfLhMXp52Y1ObrraMRh15gOe3LV08T13c5Gt3veGw2XH3ptPp9KaDJpNJer1eknGSjcWW8Yc0Sj/9vMp5vssg58ueA8xtkqSX8XicjY0vP4/P9Urh6CjZ21t0WDvOzpL9/eT4ONnZWfaama950+aTJG+Tzc3k5EU7mw4OTjMYXCx2Zy0ZjdZyeLjbyU1dfDw5T9fr4nPByUny7NnNx80Vhe3tZHf3tpPuxs6OTU0svGlldrO60t6fbTC4yNbWpJ07a0kXN3Xx8eQ8NdOlTRcNG+6NZgCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQDK/XkOHg6TtbW7mjKfs7PPb7vga970+DJZTfLhMnl52s6m0agjD6b8tqWLm7r4eHKertfF54LhsNlx96bT6fSmgyaTSXq9XpJxko3FlvGHNEo//bzKeb7LIOfLngPMbZKkl/F4nI2NLz+Pz/VK4ego2dtbdFg7zs6S/f3k+DjZ2Vn2mpmvedPmkyRvk83N5ORFNza1qcubDg5OMxhcLHtOktl35YeHu508TzZd7+Qkefbs5uPmisL2drK7e9tJd2Nnx6YmFt60MrtZXWnvz/ZVnqc7MBhcZGtrsuwZn+niebLpehcNv6/wRjMARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIA5f48Bw+HydraXU2Zz9nZ57dd8DVvenyZrCb5cJm8PO3GpjZ1edNo1JH/6PLbli6eJ5uuNxw2O+7edDqd3nTQZDJJr9dLMk6ysdgy/pBG6aefVznPdxnkfNlzgLlNkvQyHo+zsfHl5/G5XikcHSV7e4sOa8fZWbK/nxwfJzs7y14z8zVv2nyS5G2yuZmcvGhn08HBaQaDi8XurCWj0VoOD3c7+bXr4nnq4qYufu26tOnkJHn27Obj5orC9nayu3vbSXdjZ8emJhbetDK7WV1p7882GFxka2vSzp21pItfuy6epy5u6uLXrkubLho23BvNABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKAJT78xw8HCZra3c1ZT5nZ5/fdsHXvOnxZbKa5MNl8vK0nU2jUUceTPltSxe/dl08T13c1MWvXZc2DYfNjrs3nU6nNx00mUzS6/WSjJNsLLaMP6RR+unnVc7zXQY5X/YcYG6TJL2Mx+NsbHz5eXyuVwp/+ctP2dpadFg7RqO1HB7u5vg42dlZ9pqZs7Nkfz85ODjNYHCx7DlJ2jtPm0+SvE02N5OTF4ttujpPXfza2XQ9m5rp4qaTk+TZs5uPmysK/f6/ZWvrP2+76U7s7CS7u8te8bnB4CJbW5Nlz/jMwudpZXazutLe+e7i186mZmxqpkubLhp+n+qNZgCKKABQRAGAIgoAFFEAoIgCAEUUACiiAECZ64fXAGjfL+Nf8uu//zr3xz3888M86j1qdYsoACzRL+Nfsv3P23n/H+/n/tgH9x9k+A/DVsPgr48AlujXf//1VkFIkvf/8f5WrzCuIwoAFFEAoIgCAEUUACj+7yPm8+ZN0u8vdBePL5NRPl24Z6WVVQuzqRmbmpln0+OPlxndcK2Dv64lf/f/21p3PVGgmfX12e3Hj8mrVwvd1WqSfpK8XXRUe2xqxqZm5tlUx3aEKNDM8+fJDz8k794tfFcfLpO3ny7tudqR7+xsasamZubZ9OHjZd5eXF+Pv661OO4GokAzT5/O/mnBy9Nkb292reeuXKrQpmZsamaeTS/fnGbvaO/3GdaAN5oBKKIAQBEFAIooAFBEAWCJHv75YR7cf3Crj31w/0Ee/vlhq3v830cAS/So9yjDfxi6ngIAM496j1p/cr8tf30EQBEFAIooAFBEAYAiCgAUUQCgiAIApdHPKUyn0yTJv/5rkvzpDuc0d36eJJOcnCQXN1y16PcyHM5uf/45ef/eefqSq/Nk0/VsasamZn76aZLkt+fzL7k3vemIJOfn5xkMBu0sA2BpRqNR+tdcUrdRFD5+/JjXr19nfX099+7da3UgAHdvOp3m3bt3+fbbb/PNN19+56BRFAD4v8EbzQAUUQCgiAIARRQAKKIAQBEFAIooAFD+CyHopzHlKrrtAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
